{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loot hunting #\n",
    "\n",
    "You are given a link to a [single document](http://sprotasov.ru/files/AIR/a.html) on a website. This document has some internal and external links, references, forms, iframes. Crawl the website starting at the entry point and obtain the loot. Loot is given in a form of a string:\n",
    "```\n",
    "LOOT:something\\n\n",
    "```\n",
    "Find `something` and report to the instructor.\n",
    "Measure your crawling time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOID\n",
      "['LOOT:7907596de2d14092d85cd700d8d717e8']\n",
      "Time: 18.536\n",
      "You are done! Great!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import hashlib\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.parse import quote\n",
    "import urllib.parse as parse\n",
    "import re\n",
    "\n",
    "def get_links_from_page(url):\n",
    "    req = Request(url)\n",
    "    html_page = urlopen(req)    \n",
    "    links = []\n",
    "#     print(url)\n",
    "    soup = BeautifulSoup(html_page, \"lxml\")\n",
    "    # CHECKING FOR IFRAMES\n",
    "#     if (soup.body.findAll(text='LOOT')):\n",
    "#     print(str(soup.body))        \n",
    "        \n",
    "    tag = soup.find(\"iframe\")\n",
    "    if tag is not None:\n",
    "        links.append(get_page_url(tag['src']))\n",
    "    tag = soup.find(\"form\")\n",
    "    if tag is not None:\n",
    "        links.append(get_page_url(tag['action']))\n",
    "    \n",
    "    \n",
    "    for link in soup.findAll('a'):\n",
    "        links.append(link.get('href'))\n",
    "\n",
    "    return links\n",
    "\n",
    "def find_loot(url):\n",
    "    req = Request(url)\n",
    "    html_page = urlopen(req)    \n",
    "    soup = BeautifulSoup(html_page, \"lxml\")\n",
    "    if('LOOT' in str(soup.body)):\n",
    "        print(\"FOID\")\n",
    "        lines = str(soup.body).splitlines()        \n",
    "        matching = [line for line in lines if \"LOOT\" in line]\n",
    "        print(matching)\n",
    "        return matching[0].split(':')[1]\n",
    "    return \"NOTHING\"\n",
    "\n",
    "def get_page_url(page):\n",
    "    return base_url + '/{0}'.format(quote(page)).replace('%25', '%')\n",
    "\n",
    "\n",
    "url = 'http://sprotasov.ru/files/AIR/a.html'\n",
    "loot = ''\n",
    "base_url = url.split('/')[:-1]\n",
    "base_url = '/'.join(base_url)\n",
    "# print(base_url)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "## DO YOUR JOB HERE\n",
    "links = get_links_from_page(url)\n",
    "\n",
    "visited_links = []\n",
    "visited_links.append(url)\n",
    "\n",
    "queue = [] \n",
    "queue.extend(links)\n",
    "# queue.append('b.html')\n",
    "# print(get_links_from_page(get_page_url('вот%20тут%20и%20лежит%20секрет.htm')))\n",
    "while len(queue) > 0:\n",
    "    cur_page = queue.pop(0)\n",
    "#     print(cur_page)\n",
    "    visited_links.append(cur_page)\n",
    "    try:\n",
    "        possible_links = get_links_from_page(cur_page)\n",
    "        temp = find_loot(cur_page)\n",
    "    except:\n",
    "        try:\n",
    "            possible_links = get_links_from_page(get_page_url(cur_page))\n",
    "            temp = find_loot(get_page_url(cur_page))\n",
    "        except:\n",
    "            continue\n",
    "    if temp is not \"NOTHING\":\n",
    "        loot = temp\n",
    "        break\n",
    "    for link in possible_links:\n",
    "        if (link in visited_links):\n",
    "            continue\n",
    "        queue.append(link)\n",
    "        visited_links.append(link)\n",
    "    \n",
    "\n",
    "## END OF MY JOB\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time: {end - start:.3f}\")\n",
    "\n",
    "result_hash = hashlib.md5(bytes(loot, encoding='utf8')).hexdigest()\n",
    "assert result_hash == \"ebbf372b0e01ca0ce146928b1eb9aea6\", \"Loot is incorrect\"\n",
    "print(\"You are done! Great!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the template above for a local testing. For the codetest your output should contains only the loot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6b348f60023b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'input.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mloot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'some random text'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input.txt'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    with open('input.txt', 'r') as fin:\n",
    "        url = fin.read()\n",
    "\n",
    "    loot = 'some random text'\n",
    "\n",
    "    ## DO YOUR JOB HERE\n",
    "    loot = ''\n",
    "    base_url = url.split('/')[:-1]\n",
    "    base_url = '/'.join(base_url)\n",
    "    # print(base_url)\n",
    "\n",
    "    ## DO YOUR JOB HERE\n",
    "    links = get_links_from_page(url)\n",
    "\n",
    "    visited_links = []\n",
    "    visited_links.append(url)\n",
    "\n",
    "    queue = [] \n",
    "    queue.extend(links)\n",
    "    # queue.append('b.html')\n",
    "    while len(queue) > 0:\n",
    "        cur_page = queue.pop(0)\n",
    "    #     print(cur_page)\n",
    "        visited_links.append(cur_page)\n",
    "        try:\n",
    "            possible_links = get_links_from_page(cur_page)\n",
    "            temp = find_loot(cur_page)\n",
    "        except:\n",
    "            try:\n",
    "                possible_links = get_links_from_page(get_page_url(cur_page))\n",
    "                temp = find_loot(get_page_url(cur_page))\n",
    "            except:\n",
    "                continue\n",
    "        if temp is not \"NOTHING\":\n",
    "            loot = temp\n",
    "            break\n",
    "        for link in possible_links:\n",
    "            if (link in visited_links):\n",
    "                continue\n",
    "            queue.append(link)\n",
    "            visited_links.append(link)\n",
    "\n",
    "\n",
    "    ## END OF MY JOB\n",
    "\n",
    "\n",
    "    with open('output.txt', 'w') as fout:\n",
    "        fout.write(loot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
